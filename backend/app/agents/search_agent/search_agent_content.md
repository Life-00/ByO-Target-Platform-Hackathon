# 검색 에이전트

## 개요

검색 에이전트는 논문 검색 워크플로우를 조율하며, 쿼리 생성부터 PDF 다운로드까지의 과정을 담당합니다.

## 작동 방식

1. **검색 쿼리 생성**: 사용자 쿼리와 분석 목표를 LLM을 사용하여 arXiv 검색 쿼리로 변환합니다.
2. **arXiv 검색**: arXiv 검색 API를 사용하여 관련 논문을 찾습니다.
3. **결과 필터링**: LLM을 사용하여 논문의 관련성을 필터링합니다.
4. **PDF 다운로드**: 관련 논문의 PDF를 다운로드합니다.

## 사용 기술 및 도구

- **arXiv 검색 API**: 관련 논문 검색.
- **LLM 서비스**: 쿼리 생성 및 관련성 필터링.
- **PDF 다운로드**: 논문 PDF 다운로드.
- **SQLAlchemy**: 데이터베이스 상호작용.

## 주요 구성 요소

- **스키마(Schemas)**: 요청 및 응답 구조 정의.
- **프롬프트(Prompts)**: 쿼리 생성 및 관련성 평가를 위한 프롬프트 포함.
- **arXiv 검색**: arXiv에서 논문 검색 처리.
- **PDF 다운로드**: PDF 다운로드 관리.

## 주요 파일

- `agent.py`: 검색 에이전트의 주요 구현 파일.

## 평가 방법

### 결과물 평가 기준

1. **검색 품질 (Search Quality)**
   - 사용자 질문에서 생성한 arXiv 쿼리가 적절한가?
   - 검색된 논문이 연구 주제와 관련이 있는가?
   - 평가 지표: 쿼리 품질, 검색 결과 수

2. **관련성 필터링 (Relevance Filtering)**
   - LLM 기반 관련성 평가가 정확한가?
   - 규칙 기반 신뢰도 평가가 적절한가?
   - 평가 지표: 관련성 점수 (0-100), 신뢰도 점수

3. **적응형 컬오프 (Adaptive Cutoff)**
   - 검색 결과의 수준에 따라 동적으로 컬오프 조정
   - 평균보다 높은 품질의 논문만 선택
   - 평가 지표: 선택률, 품질 분포

4. **종합 평가 (Combined Scoring)**
   - LLM 관련성 (30%) + 규칙 기반 신뢰도 (70%)
   - 최종 점수 = 0.3 _ relevance + 0.7 _ reliability
   - 평가 지표: 최종 점수, 필터링 정확도

5. **PDF 다운로드 성공률 (Download Success Rate)**
   - 선택된 논문의 PDF를 성공적으로 다운로드했는가?
   - 평가 지표: 다운로드 성공률

### 평가 프로세스

```python
# 평가 예시
paper_evaluation = {
    "relevance_score": 85.0,      # LLM 관련성 점수
    "reliability_score": 92.0,    # 규칙 기반 신뢰도
    "combined_score": 89.9,        # 종합 점수 (0.3*85 + 0.7*92)
    "reliability_flags": [],       # 신뢰도 경고
    "passed_filter": True          # 필터 통과 여부
}

result = {
    "total_found": 50,             # 총 검색 결과
    "high_quality": 12,            # 고품질 논문
    "download_success": 10,        # 다운로드 성공
    "success_rate": 0.83           # 10/12 = 83%
}
```

### 품질 기준

- **후수 (>80)**: 높은 관련성과 신뢰도
- **양호 (60-80)**: 적절한 관련성, 부분적 신뢰도
- **개선 필요 (<60)**: 낮은 관련성 또는 신뢰도 문제

# 리포트 에이전트

## 개요

리포트 에이전트는 의도 기반 실행을 통해 종합적인 연구 가능성 보고서를 생성합니다.

## 작동 방식

1. **의도 분류**: 생성할 보고서 유형을 결정합니다 (예: 전체 보고서, 데이터 처리, 시각화, 빠른 분석).
2. **데이터 정규화**: 입력 데이터를 처리하고 정규화합니다.
3. **보고서 생성**: ReportBuilder를 사용하여 보고서를 작성합니다.
4. **시각화**: Visualizer를 사용하여 시각화를 생성합니다.
5. **LLM 통합**: 증거 합성과 보고서 생성을 위해 LLM을 활용합니다.

## 사용 기술 및 도구

- **LLM 서비스**: 증거 합성과 보고서 생성.
- **데이터 정규화(Data Normalizer)**: 입력 데이터 처리 및 정규화.
- **ReportBuilder**: 보고서 작성.
- **Visualizer**: 시각화 생성.
- **SQLAlchemy**: 데이터베이스 상호작용.

## 주요 구성 요소

- **스키마(Schemas)**: 요청 및 응답 구조 정의.
- **프롬프트(Prompts)**: 보고서 생성 및 증거 합성을 위한 프롬프트 포함.
- **LLM 통합**: LLM과의 상호작용 처리.
- **데이터 정규화(Data Normalizer)**: 데이터 처리 및 정규화.
- **Visualizer**: 보고서를 위한 시각화 생성.

## 주요 파일

- `agent.py`: 리포트 에이전트의 주요 구현 파일.

## 평가 방법

### 결과물 평가 기준

1. **연구 타당성 점수 (Feasibility Score)**
   - LLM이 5가지 차원을 기반으로 평가한 종합 점수 (0-100)
   - 5가지 차원: 근거 강도, 일관성, 비교가능성, 바이어스 리스크, 재현가능성
   - 평가 지표: 각 차원별 점수, 종합 타당성 점수

2. **증거 기반 평가 (Evidence-Based Assessment)**
   - 모든 평가가 문서에서 추출한 증거를 기반으로 하는가?
   - 임의의 수치나 결론 생성을 피하는가?
   - 평가 지표: 인용 포함률, 근거 추적 가능성

3. **불확실성 표현 (Uncertainty Expression)**
   - 불확실한 부분을 명시적으로 표현하는가?
   - "근거 제한적", "비교 불가" 등의 표시가 적절한가?
   - 평가 지표: 불확실성 명시률, 과대평가 방지

4. **구조화된 출력 (Structured Output)**
   - 8개 섹션 형식을 따르는가?
   - Markdown 포맷이 올바른가?
   - 평가 지표: 섹션 완성도, 포맷 준수

5. **시각화 품질 (Visualization Quality)**
   - LLM이 생성한 visualization_data가 유효한가?
   - 실제 데이터를 기반으로 한 시각화인가?
   - 평가 지표: 시각화 생성 성공률, 데이터 정확성

### 평가 프로세스

```python
# 평가 예시
result = {
    "feasibility_score": 85.0,    # 타당성 종합 점수
    "evidence_quality": 0.92,      # 증거 품질
    "uncertainty_handling": 0.88,  # 불확실성 처리
    "structure_compliance": 0.95,  # 구조 준수
    "visualization_success": 0.90, # 시각화 성공
    "overall_score": 0.90          # 종합 점수
}
```

### 타당성 점수 기준

- **매우 타당 (75-100)**: 충분한 근거와 높은 일관성
- **타당 (50-75)**: 제한적 근거나 일부 상충
- **추가 검토 (<50)**: 불충분한 근거 또는 상충된 결과
